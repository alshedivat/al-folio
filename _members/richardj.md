---
name: Richard Johansson
image: "https://www.cse.chalmers.se/~richajo/content/passosella.jpg"
position: Associate professor
state: current
start-date: 2016-04-01
end-date: YY-MM-DD
email: richard.johansson@gu.se
scholar_userid: FvhWYU8AAAAJ
publons_id:
research_gate_profile:
github_username:
linkedin_username:
twitter_username:
medium_username:
blogger_url:
description: >
  My research field is *natural language processing*: in our research group, we develop machine learning models and algorithms that analyse language written by humans.

  I have worked on variety of research problems within the field of NLP and my interests are quite wide. A common thread in the various research projects is that they are related to high-level questions such as: *What information does this text express? How can the computer determine what this text means?* To make some progress on these high-level goals, we need to be cross-disciplinary: we have to apply methods and models not only from machine learning but also fields such as linguistics, information theory, statistics, and algorithms.

  Most of the current research in our group involves questions around *learned representations* of words and text. Is it possible to *improve the representations by grounding* them in other information sources? *How are NLP systems influenced* by the information in the representations? For instance, we have tried to use visual information when training text representations and we have developed different training methods for visual supervision. To investigate how text representations are affected by the visual training, we designed experimental protocols to measure these effects. In addition to the visual modality, we are interested in representation models that combine text-based supervision with different types of structured knowledge, and we developed a number of methods for injecting such knowledge into word representations, either as a post-processing step or during training. In a recently started project, we will investigate how text-based causal inference methods are influenced by text representations, and develop new methods to control what information is expressed by representations.

  In my earlier research, until around 2013, many of the research projects involved defining some sort of *structured representation* of the meaning content of a text, and the job of the machine would then be to extract this type of structure automatically from the text. Most of my work as a PhD student focused on machine learning models and algorithms for extracting different types of event representations: for instance, we developed systems that extract semantic roles and semantic frames. I also developed algorithms for integrating dependency parsing and semantic role labeling. Similar methods could also be applied for extracting opinion structures.
---
