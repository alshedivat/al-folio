---
---

@string{aps = {American Physical Society,}}

@article{flipad,
  title = {Single-Model Attribution of Generative Models Through Final-Layer Inversion},
  author = {Laszkiewicz, Mike and Ricker, Jonas and Lederer, Johannes and Fischer, Asja},
  journal={(Under Review)},
  year={2023},
  selected={true},
  preview={flipad_logo.png},
  abstract={Recent groundbreaking developments on genera-
tive modeling have sparked interest into practical
single-model attribution tools. Such methods pre-
dict whether a sample was generated by a specific
generator or not, for instance, to prove intellectual
property theft. However, previous works are ei-
ther limited to the closed-world setting or require
undesirable changes of the generative model. We
address these shortcomings by (i) adapting ex-
isting methods to the open-world setting and (ii)
proposing FLIPAD, a new approach for single-
model attribution in the open-world setting based
on final-layer inversion and anomaly detection.
We show that final-layer inversion can be reduced
to a convex lasso optimization problem, making
our approach theoretically sound and computa-
tionally efficient. The theoretical findings are
accompanied by an experimental study demon-
strating the effectiveness of our approach, outper-
forming the adapted existing methods.
}
  }
  
@InProceedings{mtaf,
  title = 	 {Marginal Tail-Adaptive Normalizing Flows},
  author =       {Laszkiewicz, Mike and Lederer, Johannes and Fischer, Asja},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning (ICML)},
  pages = 	 {12020--12048},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  selected={true},
  preview={mtaf_logo.png},
  abstract={Learning the tail behavior of a distribution is a notoriously difficult problem. By definition, the number of samples from the tail is small, and deep generative models, such as normalizing flows, tend to concentrate on learning the body of the distribution. In this paper, we focus on improving the ability of normalizing flows to correctly capture the tail behavior and, thus, form more accurate models. We prove that the marginal tailedness of an autoregressive flow can be controlled via the tailedness of the marginals of its base distribution. This theoretical insight leads us to a novel type of flows based on flexible base distributions and data-driven linear layers. An empirical analysis shows that the proposed method improves on the accuracy{—}especially on the tails of the distribution{—}and is able to generate heavy-tailed data. We demonstrate its application on a weather and climate example, in which capturing the tail behavior is essential.
},
  pdf={https://proceedings.mlr.press/v162/laszkiewicz22a/laszkiewicz22a.pdf}
}

@InProceedings{copula,
  title={Copula-based normalizing flows},
  abstract={Normalizing flows, which learn a distribution by
transforming the data to samples from a Gaussian
base distribution, have proven powerful density
approximators. But their expressive power is limited by this choice of the base distribution. We,
therefore, propose to generalize the base distribution to a more elaborate copula distribution to
capture the properties of the target distribution
more accurately. In a first empirical analysis, we
demonstrate that this replacement can dramatically improve the vanilla normalizing flows in
terms of flexibility, stability, and effectivity for
heavy-tailed data. Our results suggest that the
improvements are related to an increased local
Lipschitz-stability of the learned flow.},
  pdf={https://arxiv.org/pdf/2107.07352.pdf},
  author={Laszkiewicz, Mike and Lederer, Johannes and Fischer, Asja},
  booktitle={Invertible Neural Networks, Normalizing Flows, and Explicit Likelihood Models (INNF+)
},
  year={2021},
  selected={true},
  preview={copula_nfs_logo.png}
}

@InProceedings{thav,
  title={Thresholded adaptive validation: Tuning the graphical lasso for graph recovery},
  author={Laszkiewicz, Mike and Fischer, Asja and Lederer, Johannes},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={1864--1872},
  year={2021},
  organization={PMLR},
  selected={true},
  preview={thav_logo.png},
  abstract={Many Machine Learning algorithms are formulated as regularized optimization problems,
but their performance hinges on a regularization parameter that needs to be calibrated
to each application at hand. In this paper,
we propose a general calibration scheme for
regularized optimization problems and apply
it to the graphical lasso, which is a method
for Gaussian graphical modeling. The scheme
is equipped with theoretical guarantees and
motivates a thresholding pipeline that can improve graph recovery. Moreover, requiring at
most one line search over the regularization
path, the calibration scheme is computationally more efficient than competing schemes
that are based on resampling. Finally, we
show in simulations that our approach can
improve on the graph recovery of other approaches considerably.},
  pdf={http://proceedings.mlr.press/v130/laszkiewicz21a/laszkiewicz21a.pdf}
}