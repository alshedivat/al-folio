---
---

@Article{doi:10.3109/10929088.2014.891657,
  author    = {Dominik Spinczyk and Adam Karwan and Marcin Copik},
  journal   = {Computer Aided Surgery},
  title     = {Methods for abdominal respiratory motion tracking},
  year      = {2014},
  number    = {1-3},
  pages     = {34-47},
  volume    = {19},
  doi       = {10.3109/10929088.2014.891657},
  eprint    = {https://doi.org/10.3109/10929088.2014.891657},
  publisher = {Taylor & Francis},
  url       = {https://doi.org/10.3109/10929088.2014.891657},
  abstract = {Non-invasive surface registration methods have been developed to register and track breathing motions in a patient's abdomen and thorax. We evaluated several different registration methods, including marker tracking using a stereo camera, chessboard image projection, and abdominal point clouds. Our point cloud approach was based on a time-of-flight (ToF) sensor that tracked the abdominal surface. We tested different respiratory phases using additional markers as landmarks for the extension of the non-rigid Iterative Closest Point (ICP) algorithm to improve the matching of irregular meshes. Four variants for retrieving the correspondence data were implemented and compared. Our evaluation involved 9 healthy individuals (3 females and 6 males) with point clouds captured in opposite breathing phases (i.e., inhalation and exhalation). We measured three factors: surface distance, correspondence distance, and marker error. To evaluate different methods for computing the correspondence measurements, we defined the number of correspondences for every target point and the average correspondence assignment error of the points nearest the markers.},
  html = {https://doi.org/10.3109/10929088.2014.891657},
  pdf = {2014_respiratory_motion_cas_paper.pdf},
}

@inproceedings{DBLP:conf/csp/CopikRW16,
  author    = {Marcin Copik and
            Artur Rataj and
                           Bozena Wozna{-}Szczesniak},
  editor    = {Bernd{-}Holger Schlingloff},
  title     = {A GPGPU-based Simulator for Prism: Statistical Verification of Results
              of {PMC} (extended abstract)},
  booktitle = {Proceedings of the 25th International Workshop on Concurrency, Specification
            and Programming, Rostock, Germany, September 28-30, 2016},
  series    = {{CEUR} Workshop Proceedings},
  volume    = {1698},
  pages     = {199--208},
  publisher = {CEUR-WS.org},
  year      = {2016},
  url       = {http://ceur-ws.org/Vol-1698/CS\&P2016\_19\_Copik\&Rataj\&Wozna-Szczesniak\_A-GPGPU-based-Simulator-for-Prism-Statistical-Verification-of-Results-of-PMC.pdf},
  timestamp = {Wed, 12 Feb 2020 16:45:14 +0100},
  biburl    = {https://dblp.org/rec/conf/csp/CopikRW16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  code = {https://github.com/mcopik/prism-fastsim},
  html = {http://ceur-ws.org/Vol-1698/},
  pdf = {2016_prism_gpu_csp_paper.pdf},
  slides = {2016_prism_gpu_csp_slides.pdf},
  abstract = {We describe a GPGPU–based Monte Carlo simulator integrated with Prism. It supports Markov chains with discrete or continuous time and a subset of properties expressible in PCTL, CSL and their variants extended with rewards. The simulator allows an automated statistical verification of results obtained using Prism’s formal methods.}
}

@inproceedings{10.1145/3078155.3078187,
  author = {Copik, Marcin and Kaiser, Hartmut},
  title = {Using SYCL as an Implementation Framework for HPX.Compute},
  year = {2017},
  isbn = {9781450352147},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3078155.3078187},
  doi = {10.1145/3078155.3078187},
  abstract = {The recent advancements in High Performance Computing and ongoing research to reach Exascale has been heavily supported by introducing dedicated massively parallel accelerators. Programmers wishing to maximize utilization of current supercomputers are required to develop software which not only involves scaling across multiple nodes but are capable of offloading data-parallel computation to dedicated hardware such as graphic processors. Introduction of new types of hardware has been followed by developing new languages, extensions, compilers and libraries. Unfortunately, none of those solutions seem to be fully portable and independent from specific vendor and type of hardware.HPX.Compute, a programming model developed on top of HPX, a C++ standards library for concurrency and parallelism, uses existing and proposed C++ language and library capabilities to support various types of parallelism. It aims to provide a generic interface allowing for writing code which is portable between hardware architectures.We have implemented a new backend for HPX.Compute based on SYCL, a Khronos standard for single-source programming of OpenCL devices in C++. We present how this runtime may be used to target OpenCL devices through our C++ API. We have evaluated performance of new implementation on graphic processors with STREAM benchmark and compare results with existing CUDA-based implementation.},
  booktitle = {Proceedings of the 5th International Workshop on OpenCL},
  articleno = {30},
  numpages = {7},
  keywords = {GPGPU, parallel programming, SYCL, C++, heterogeneous programming, HPX},
  location = {Toronto, Canada},
  series = {IWOCL 2017},
  slides = {2017_hpx_compute_iwocl_slides.pdf},
  html = {https://dl.acm.org/doi/10.1145/3078155.3078187},
  pdf = {2017_hpx_compute_iwocl_paper.pdf},
}

@inproceedings{10.1145/3168804,
  author = {Barthels, Henrik and Copik, Marcin and Bientinesi, Paolo},
  title = {The Generalized Matrix Chain Algorithm},
  year = {2018},
  isbn = {9781450356176},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3168804},
  doi = {10.1145/3168804},
  abstract = {In this paper, we present a generalized version of the matrix chain algorithm to generate efficient code for linear algebra problems, a task for which human experts often invest days or even weeks of works. The standard matrix chain problem consists in finding the parenthesization of a matrix product M := A1 A2 ⋯ An that minimizes the number of scalar operations. In practical applications, however, one frequently encounters more complicated expressions, involving transposition, inversion, and matrix properties. Indeed, the computation of such expressions relies on a set of computational kernels that offer functionality well beyond the simple matrix product. The challenge then shifts from finding an optimal parenthesization to finding an optimal mapping of the input expression to the available kernels. Furthermore, it is often the case that a solution based on the minimization of scalar operations does not result in the optimal solution in terms of execution time. In our experiments, the generated code outperforms other libraries and languages on average by a factor of about 9. The motivation for this work comes from the fact that—despite great advances in the development of compilers—the task of mapping linear algebra problems to optimized kernels is still to be done manually. In order to relieve the user from this complex task, new techniques for the compilation of linear algebra expressions have to be developed.},
  booktitle = {Proceedings of the 2018 International Symposium on Code Generation and Optimization},
  pages = {138–148},
  numpages = {11},
  keywords = {matrix chain problem, linear algebra, compiler},
  location = {Vienna, Austria},
  series = {CGO 2018},
  arxiv = {1804.04021},
  html = {https://dl.acm.org/doi/10.1145/3168804},
  pdf = {2018_matrix_chain_cgo_paper.pdf}
}

@InProceedings{10.1007/978-3-030-47956-5_15,
  author="Calotoiu, Alexandru
  and Copik, Marcin
  and Hoefler, Torsten
  and Ritter, Marcus
  and Shudler, Sergei
  and Wolf, Felix",
  editor="Bungartz, Hans-Joachim
  and Reiz, Severin
  and Uekermann, Benjamin
  and Neumann, Philipp
  and Nagel, Wolfgang E.",
  title="ExtraPeak: Advanced Automatic Performance Modeling for HPC Applications",
  booktitle="Software for Exascale Computing - SPPEXA 2016-2019",
  year="2020",
  publisher="Springer International Publishing",
  address="Cham",
  pages="453--482",
  abstract="Performance models are powerful tools allowing developers to understand the behavior of their applications, and empower them to address performance issues already during the design or prototyping phase. Unfortunately, the difficulties of creating such models manually and the effort involved render performance modeling a topic limited to a relatively small community of experts. This article summarizes the results of the two projects Catwalk, which aimed to create tools that automate key activities of the performance modeling process, and ExtraPeak, which built upon the results of Catwalk and worked toward making this powerful methodology more flexible, streamlined and easy to use. The sew projects both provide accessible tools and methods that bring performance modeling to a wider audience of HPC application developers. Since its outcome represents the final state of the two projects, we expand to a greater extent on the results of ExtraPeak.",
  isbn="978-3-030-47956-5",
  html = {https://link.springer.com/chapter/10.1007/978-3-030-47956-5_15},
  pdf = {2020_extrapeak_paper.pdf}
}

@article{2017prefixsum,
  title={Parallel Prefix Algorithms for the Registration of Arbitrarily Long Electron Micrograph Series}, 
  author={Marcin Copik and Paolo Bientinesi and Benjamin Berkels},
  year={2017},
  pdf = {2017_prefix_sum_abstract_SC.pdf},
  poster = {2017_prefix_sum_poster_SC.pdf},
  abstract = {Recent advances in the technology of transmission electron microscopy have allowed for a more precise visualization of materials and physical processes, such as metal oxidation. Nevertheless, the quality of information is limited by the damage caused by an electron beam, movement of the specimen or other environmental factors. A novel registration method has been proposed to remove those limitations by acquiring a series of low dose microscopy frames and performing a computational registration on them to understand and visualize the sample. This process can be represented as a prefix sum with a complex and computationally intensive binary operator and a parallelization is necessary to enable processing long series of microscopy images. With our parallelization scheme, the time of registration of results from ten seconds of microscopy acquisition has been decreased from almost thirteen hours to less than seven minutes on 512 Intel IvyBridge cores.},
  html = {https://sc17.supercomputing.org/SC17%20Archive/src_poster/src_poster_pages/spost118.html},
  journal = {ACM Student Research Competition at ACM/IEEE Supercomputing}
}

@article{2017masterthesis,
  title={Parallel Prefix Algorithms for the Registration of Arbitrarily Long Electron Micrograph Series}, 
  author={Marcin Copik},
  year={2017},
  pdf = {2017_prefix_sum_thesis.pdf},
  journal = {Master Thesis},
  abstract = {Recent advances in the technology of transmission electron microscopy have allowed for a more precise visualization of materials and physical processes, such as metal oxidation. Nevertheless, the quality of information is limited by the damage caused by an electron beam, movement of the specimen or other environmental factors. A novel registration method has been proposed to remove those limitations by acquiring a series of low dose microscopy frames and performing a computational registration on them to understand and visualize the sample. This process can be represented as a prefix sum with a complex and computationally intensive binary operator and a parallelization is necessary to enable processing long series of microscopy images. With our parallelization scheme, the time of registration of results from ten seconds of microscopy acquisition has been decreased from almost thirteen hours to less than seven minutes on 512 Intel IvyBridge cores.},
  arxiv = {1712.02533}
}

@misc{2021rfaas,
  title={RFaaS: RDMA-Enabled FaaS Platform for Serverless High-Performance Computing}, 
  author={Marcin Copik and Konstantin Taranov and Alexandru Calotoiu and Torsten Hoefler},
  year={2021},
  eprint={2106.13859},
  arxiv={2106.13859},
  archivePrefix={arXiv},
  primaryClass={cs.DC},
  abstract={The rigid MPI programming model and batch scheduling dominate high-performance computing. While clouds brought new levels of elasticity into the world of computing, supercomputers still suffer from low resource utilization rates. To enhance supercomputing clusters with the benefits of serverless computing, a modern cloud programming paradigm for pay-as-you-go execution of stateless functions, we present rFaaS, the first RDMA-aware Function-as-a-Service (FaaS) platform. With hot invocations and decentralized function placement, we overcome the major performance limitations of FaaS systems and provide low-latency remote invocations in multi-tenant environments. We evaluate the new serverless system through a series of microbenchmarks and show that remote functions execute with negligible performance overheads. We demonstrate how serverless computing can bring elastic resource management into MPI-based high-performance applications. Overall, our results show that MPI applications can benefit from modern cloud programming paradigms to guarantee high performance at lower resource costs.},
  code={https://github.com/spcl/rFaaS/}
}

@periodical{2020prefixsum,
  title={Work-stealing prefix scan: Addressing load imbalance in large-scale image registration}, 
  author={Marcin Copik and Tobias Grosser and Torsten Hoefler and Paolo Bientinesi and Benjamin Berkels},
  year={2021},
  eprint={2010.12478},
  archivePrefix={arXiv},
  primaryClass={cs.DC},
  arxiv = {2010.12478},
  pdf = {2021_prefix_sum_TPDS.pdf},
  code = {https://github.com/berkels/match-series/},
  type = {article},
  journal = {IEEE Transactions on Parallel and Distributed Systems (TPDS) (to appear)},
  abstract = {
    Parallelism patterns (e.g., map or reduce) have proven to be effective tools for parallelizing high-performance applications. In this paper, we study the recursive registration of a series of electron microscopy images - a time consuming and imbalanced computation necessary for nano-scale microscopy analysis. We show that by translating the image registration into a specific instance of the prefix scan, we can convert this seemingly sequential problem into a parallel computation that scales to over thousand of cores. We analyze a variety of scan algorithms that behave similarly for common low-compute operators and propose a novel work-stealing procedure for a hierarchical prefix scan. Our evaluation shows that by identifying a suitable and well-optimized prefix scan algorithm, we reduce time-to-solution on a series of 4,096 images spanning ten seconds of microscopy acquisition from over 10 hours to less than 3 minutes (using 1024 Intel Haswell cores), enabling derivation of material properties at nanoscale for long microscopy image series. 
  }
}

@inproceedings{copik2020sebs,
  title={SeBS: A Serverless Benchmark Suite for Function-as-a-Service Computing}, 
  author={Marcin Copik and Grzegorz Kwasniewski and Maciej Besta and Michal Podstawski and Torsten Hoefler},
  year={2021},
  eprint={2012.14132},
  arxiv={2012.14132},
  archivePrefix={arXiv},
  primaryClass={cs.DC},
  abstract = {Function-as-a-Service (FaaS) is one of the most promising directions for the future of cloud services, and serverless functions have immediately become a new middleware for building scalable and cost-efficient microservices and applications. However, the quickly moving technology hinders reproducibility, and the lack of a standardized benchmarking suite leads to ad-hoc solutions and microbenchmarks being used in serverless research, further complicating metaanalysis and comparison of research solutions. To address this challenge, we propose the Serverless Benchmark Suite: the first benchmark for FaaS computing that systematically covers a wide spectrum of cloud resources and applications. Our benchmark consists of the specification of representative workloads, the accompanying implementation and evaluation infrastructure, and the evaluation methodology that facilitates reproducibility and enables interpretability. We demonstrate that the abstract model of a FaaS execution environment ensures the applicability of our benchmark to multiple commercial providers such as AWS, Azure, and Google Cloud. Our work facilities experimental evaluation of serverless systems, and delivers a standardized, reliable and evolving evaluation methodology of performance, efficiency, scalability and reliability of middleware FaaS platforms.},
  code = {https://github.com/spcl/serverless-benchmarks},
  booktitle = {Proceedings of the 22nd International Middleware Conference (to appear)},
  series = {Middleware '21}
}

@article{2019perftaint,
  title={perf-taint: Taint Analysis for Automatic Many-Parameter Performance Modeling},
  author={Marcin Copik and Torsten Hoefler},
  year={2019},
  pdf = {2019_perf_taint_abstract.pdf},
  poster = {2019_perf_taint_poster.pdf},
  slides = {2019_perf_taint_slides.pdf},
  abstract = {Performance modeling is a well-known technique for understanding the scaling behavior of an application. Although the modeling process is today often automatic, it still relies on a domain expert selecting program parameters and deciding relevant sampling intervals. Since existing empirical methods attempt blackbox modeling, the decision on which parameters influence a selected part of the program is based on measured data, making empirical modeling sensitive to human errors and instrumentation noise. We introduce a hybrid analysis to mitigate the current limitations of empirical modeling, combining the confidence of static analysis with the ability of dynamic taint analysis to capture the effects of control-flow and memory operations. We construct models of computation and communication volumes that help the modeler to remove effects of noise and improve the correctness of estimated models. Our automatic analysis prunes irrelevant program parameters and brings an understanding of parameter dependencies which helps in designing the experiment.},
  html = {https://sc19.supercomputing.org/proceedings/src_poster/src_poster_pages/spostg110.html},
  journal = {ACM Student Research Competition at ACM/IEEE Supercomputing},
  note = {Gold Medal in the competition}
}

@inproceedings{2021perftaint,
  author = {Copik, Marcin and Calotoiu, Alexandru and Grosser, Tobias and Wicki, Nicolas and Wolf, Felix and Hoefler, Torsten},
  title = {Extracting Clean Performance Models from Tainted Programs},
  year = {2021},
  isbn = {9781450382946},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3437801.3441613},
  doi = {10.1145/3437801.3441613},
  abstract = {Performance models are well-known instruments to understand the scaling behavior of parallel applications. They express how performance changes as key execution parameters, such as the number of processes or the size of the input problem, vary. Besides reasoning about program behavior, such models can also be automatically derived from performance data. This is called empirical performance modeling. While this sounds simple at the first glance, this approach faces several serious interrelated challenges, including expensive performance measurements, inaccuracies inflicted by noisy benchmark data, and overall complex experiment design, starting with the selection of the right parameters. The more parameters one considers, the more experiments are needed and the stronger the impact of noise. In this paper, we show how taint analysis, a technique borrowed from the domain of computer security, can substantially improve the modeling process, lowering its cost, improving model quality, and help validate performance models and experimental setups.},
  booktitle = {Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
  pages = {403–417},
  numpages = {15},
  keywords = {performance modeling, high-performance computing, compiler techniques, LLVM, taint analysis},
  location = {Virtual Event, Republic of Korea},
  series = {PPoPP '21},
  arxiv = {2012.15592},
  html = {https://dl.acm.org/doi/10.1145/3437801.3441613},
  pdf = {2021_perf_taint_ppopp.pdf},
  code = {https://github.com/spcl/perf-taint/},
  recording = {https://www.youtube.com/watch?v=eGEvFXK4owc},
  slides = {2021_perf_taint_ppopp_slides.pdf},
  artifact = {https://zenodo.org/record/4381803}
}

@article{besta2021graphminesuite,
  title={GraphMineSuite: Enabling High-Performance and Programmable Graph Mining Algorithms with Set Algebra}, 
  author={Maciej Besta and Zur Vonarburg-Shmaria and Yannick Schaffner and Leonardo Schwarz and Grzegorz Kwasniewski and Lukas Gianinazzi and Jakub Beranek and Kacper Janda and Tobias Holenstein and Sebastian Leisinger and Peter Tatkowski and Esref Ozdemir and Adrian Balla and Marcin Copik and Philipp Lindenberger and Pavel Kalvoda and Marek Konieczny and Onur Mutlu and Torsten Hoefler},
  year={2021},
  eprint={2103.03653},
  arxiv={2103.03653},
  archivePrefix={arXiv},
  primaryClass={cs.DC},
  journal={arXiv},
  abstract = {We propose GraphMineSuite (GMS): the first benchmarking suite for graph mining that facilitates evaluating and constructing high-performance graph mining algorithms. First, GMS comes with a benchmark specification based on extensive literature review, prescribing representative problems, algorithms, and datasets. Second, GMS offers a carefully designed software platform for seamless testing of different fine-grained elements of graph mining algorithms, such as graph representations or algorithm subroutines. The platform includes parallel implementations of more than 40 considered baselines, and it facilitates developing complex and fast mining algorithms. High modularity is possible by harnessing set algebra operations such as set intersection and difference, which enables breaking complex graph mining algorithms into simple building blocks that can be separately experimented with. GMS is supported with a broad concurrency analysis for portability in performance insights, and a novel performance metric to assess the throughput of graph mining algorithms, enabling more insightful evaluation. As use cases, we harness GMS to rapidly redesign and accelerate state-of-the-art baselines of core graph mining problems: degeneracy reordering (by up to >2x), maximal clique listing (by up to >9x), k-clique listing (by 1.1x), and subgraph isomorphism (by up to 2.5x), also obtaining better theoretical performance bounds.
  }
}

@article{besta2021sisa,
  title={SISA: Set-Centric Instruction Set Architecture for Graph Mining on Processing-in-Memory Systems}, 
  author={Maciej Besta and Raghavendra Kanakagiri and Grzegorz Kwasniewski and Rachata Ausavarungnirun and Jakub Beránek and Konstantinos Kanellopoulos and Kacper Janda and Zur Vonarburg-Shmaria and Lukas Gianinazzi and Ioana Stefan and Juan Gómez Luna and Marcin Copik and Lukas Kapp-Schwoerer and Salvatore Di Girolamo and Marek Konieczny and Onur Mutlu and Torsten Hoefler},
  year={2021},
  eprint={2104.07582},
  arxiv={2104.07582},
  archivePrefix={arXiv},
  primaryClass={cs.AR},
  journal={arXiv},
  url={https://arxiv.org/abs/2104.07582},
  abstract={Simple graph algorithms such as PageRank have recently been the target of numerous hardware accelerators. Yet, there also exist much more complex graph mining algorithms for problems such as clustering or maximal clique listing. These algorithms are memory-bound and thus could be accelerated by hardware techniques such as Processing-in-Memory (PIM). However, they also come with non-straightforward parallelism and complicated memory access patterns. In this work, we address this with a simple yet surprisingly powerful observation: operations on sets of vertices, such as intersection or union, form a large part of many complex graph mining algorithms, and can offer rich and simple parallelism at multiple levels. This observation drives our cross-layer design, in which we (1) expose set operations using a novel programming paradigm, (2) express and execute these operations efficiently with carefully designed set-centric ISA extensions called SISA, and (3) use PIM to accelerate SISA instructions. The key design idea is to alleviate the bandwidth needs of SISA instructions by mapping set operations to two types of PIM: in-DRAM bulk bitwise computing for bitvectors representing high-degree vertices, and near-memory logic layers for integer arrays representing low-degree vertices. Set-centric SISA-enhanced algorithms are efficient and outperform hand-tuned baselines, offering more than 10x speedup over the established Bron-Kerbosch algorithm for listing maximal cliques. We deliver more than 10 SISA set-centric algorithm formulations, illustrating SISA's wide applicability.
  }
}
