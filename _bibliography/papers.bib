---
---

@inproceedings{ponton2024stretchyourreach,
bibtex_show = {true},
selected = {true},
preview = {stretchyourreach.gif},
pdf = {stretchyourreach_chi24.pdf},
video = {https://youtu.be/e1-LuHWDjLU},
author = {Ponton, Jose Luis and Keshavarz, Reza and Beacco, Alejandro and Pelechano, Nuria},
title = {Stretch your reach: Studying Self-Avatar and Controller Misalignment in Virtual Reality Interaction},
month = {May},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642268},
doi = {10.1145/3613904.3642268},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {109},
numpages = {15},
series = {CHI '24},
abstract = {In VR, misalignment between the user's body and their virtual avatar can disrupt the sense of embodiment and hinder interaction. This study examines five different interaction modes, manipulating factors like virtual controller visibility and hand positioning. The results reveal that "stretching" the avatar's arms to align with the user's hands significantly improves embodiment, proprioception, user preference, and task performance. Interestingly, whether the virtual controllers are rendered or not had no significant impact.}
}

@INPROCEEDINGS{10494178,
  bibtex_show = {true},
  selected = {true},
  preview = {expectedcollision.gif},
  pdf = {expectedcollisionfeedback_ieeevr24.pdf},
  video = {https://youtu.be/DoG37fthIZE},
  author={Yun, Haoran and Ponton, Jose Luis and Beacco, Alejandro and Andujar, Carlos and Pelechano, Nuria},
  booktitle={2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)}, 
  title={Exploring the Role of Expected Collision Feedback in Crowded Virtual Environments}, 
  month = {March},
  year={2024},
  pages={472-481},
  publisher = {{IEEE}},
  doi={10.1109/VR58804.2024.00068},
  abstract = {This study investigates the impact of expected collision feedback on user perception and interaction in virtual environments populated with virtual humans.  We examine common feedback techniques (auditory, tactile) and the effect of inducing the expectation of a physical collision with a real person. Results indicate that expected collision feedback significantly influences both global navigation and local movements, as well as subjective perceptions of presence and copresence.}
}


@article{ponton2023sparseposer,
bibtex_show = {true},
selected = {true},
preview = {sparseposer.gif},
pdf = {sparseposer_siggraphasia2023.pdf},
code = {https://github.com/UPC-ViRVIG/SparsePoser},
website = {https://upc-virvig.github.io/SparsePoser/},
video = {https://youtu.be/BAi4KoHtehY},
author = {Ponton, Jose Luis and Yun, Haoran and Aristidou, Andreas and Andujar, Carlos and Pelechano, Nuria},
title = {SparsePoser: Real-Time Full-Body Motion Reconstruction from Sparse Data},
year = {2023},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
booktitle = {SIGGRAPH Asia 2023},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {0730-0301},
url = {https://doi.org/10.1145/3625264},
doi = {10.1145/3625264},
abstract = {SparsePoser is a novel deep learning-based approach for reconstructing full-body human motion in VR using a reduced set of six tracking devices. By learning the human motion manifold from motion capture data and incorporating a learned IK component, it overcomes the limitations of traditional IK methods and IMU-based approaches, producing high-quality, continuous poses. Our extensive evaluations on motion capture datasets and real-time demos demonstrate that SparsePoser outperforms state-of-the-art techniques and can be applied to users with varying body dimensions.},
journal = {ACM Trans. Graph.},
month = {oct},
articleno = {5},
numpages = {14},
}


@article{ponton2023fittedavatars,
  bibtex_show = {true},
  title = {Fitted avatars: automatic skeleton adjustment for self-avatars in virtual reality},
  author = {Ponton, Jose Luis and Ceballos, Victor and Acosta, Lesly and Rios, Alejandro and Monclus, Eva and Pelechano, Nuria},
  journal = {Virtual Reality},
  pages = {2541--2560},
  issn = {1434-9957},
  month = jul,
  year = {2023},
  volume = {27},
  publisher = {Springer},
  selected = {true},
  preview = {fittedavatars.gif},
  pdf = {fittedavatars_vr2023.pdf},
  DOI = {10.1007/s10055-023-00821-z},
  video = {https://youtu.be/U7KOhTGByyc},
  abstract = {Self-avatars are essential for enhancing presence and communication in VR.  However, ensuring accurate dimensions often requires manual measurements, which can be time-consuming and error-prone. This paper proposes an automatic method using a head-mounted display (HMD), hand controllers, and trackers to accurately estimate user measurements and adjust the virtual skeleton. This method improves the alignment of the avatar with the user's body, surpassing solutions that rely on uniform scaling or assumptions about joint locations.}
}

@inproceedings{yun2023animationfidelity,
	bibtex_show = {true},
	booktitle = {2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR)},
	title = {{Animation Fidelity in Self-Avatars: Impact on User Performance and Sense of Agency}},
	author = {Yun, Haoran and Ponton, Jose Luis and Andujar, Carlos and Pelechano, Nuria},
	year = {2023},
	month = {March},
	publisher = {{IEEE}},
	pages = {286-296},
	ISSN = {2642-5254},
	preview = {animationfidelity.gif},
	selected = {true},
	pdf = {animation_fidelity_ieeevr23.pdf},
	DOI = {10.1109/VR55154.2023.00044},
	video = {https://youtu.be/X1POhdDIvm0?si=SnPHPOAxrmu3lERO},
	abstract = {This research investigates the impact of avatar animation fidelity on various tasks in VR. Comparing three animation techniques (two using Inverse Kinematics and one using a motion capture system), the study found that the quality of animation influences the user's sense of embodiment. Surprisingly, IK-based solutions, despite using fewer sensors, sometimes outperformed MoCap in tasks requiring precise positioning due to lower latency and less positional drift.}
}	
	
@article{ponton2022mmvr,
	bibtex_show={true},
	author = {Ponton, Jose Luis and Yun, Haoran and Andujar, Carlos and Pelechano, Nuria},
    title = {{Combining Motion Matching and Orientation Prediction to Animate Avatars for Consumer-Grade VR Devices}},
	booktitle = {ACM SIGGRAPH / Eurographics Symposium on Computer Animation},
    journal = {Computer Graphics Forum},
	volume = {41},
	number = {8},
	pages = {107-118},
	ISSN = {1467-8659},
	DOI = {10.1111/cgf.14628},
	year  = {2022},
	month = {September},
	preview = {mmvr.gif},
	selected = {true},
	code = {https://github.com/UPC-ViRVIG/MMVR},
	website = {https://upc-virvig.github.io/MMVR/},
	pdf = {mmvr_sca2022.pdf},
	video = {https://youtu.be/crU9oLX0GnM},
	abstract = {Current VR avatar animation methods suffer from inaccurate lower body movement due to the limited tracking data available from consumer-grade devices. This paper presents a novel approach that utilizes a neural network to estimate user body orientation from HMD and controller inputs. By combining this orientation data with HMD velocity and rotation, a feature vector is generated to drive a motion matching algorithm. Tested on a MoCap database of VR users, this system produces a wider range of lower body animations that precisely match user orientation, enabling more realistic and diverse movement representation in VR.}
}

@inproceedings {ponton2022avatargo,
  bibtex_show={true},
  booktitle = {Eurographics 2022 - Short Papers},
  title = {{AvatarGo: Plug and Play self-avatars for VR}},
  author = {Ponton, Jose Luis and Monclus, Eva and Pelechano, Nuria},
  month = {May},
  year = {2022},
  publisher = {The Eurographics Association},
  ISSN = {1017-4656},
  ISBN = {978-3-03868-169-4},
  doi = {10.2312/egs.20221037},
  preview = {avatargo.gif},
  selected = {true},
  video = {https://youtu.be/DWU4p-a-uXo},
  code = {https://github.com/UPC-ViRVIG/AvatarGo},
  pdf = {avatarGo_shortEG2022.pdf},
  abstract={Self-avatars in VR can greatly enhance user experience, especially in collaborative settings. Current methods for animating avatars can lead to mismatches between the user's movement and the avatar's. This paper introduces a simple but effective technique for calculating precise offsets for each user, resulting in significantly improved avatar movement and a stronger sense of embodiment.}
}

@article{mohammadreza2024padelvic,
  bibtex_show={true},
  author = {Mohammadreza, Javadiha and Andujar, Carlos and Calvanese, Michele and Lacasa, Enrique and Moyes, Jordi and Ponton, Jose Luis and Susin, Antonio and Wang, Jiabo},
  title = {{PADELVIC: Multicamera Videos and Motion Capture Data in Padel Matches}},
  year = {2024},
  month = jan,
  journal = {Padel Scientific Journal},
  volume = {2},
  number = {1},
  pages = {89--106},
  doi = {10.17398/2952-2218.2.89},
  preview = {padelvic.gif},
  pdf = {padelvic_padel24.pdf},
  website = {https://github.com/UPC-ViRVIG/PadelVic},
  abstract = {PadelVic is an annotated dataset of an amateur padel match, featuring multi-view video streams, estimated positional data for all players, and motion capture data for one player. It also includes synthetic videos for training neural networks to estimate positional data. With its high accuracy, especially in the synthetic dataset, PadelVic is a valuable tool for researchers interested in automatic sports video analysis, player tracking, and tactical analysis.}
}
