---
---
  

@article{aistats24,
  title = {Oral presentation at AISTATS, Valencia, Spain},
  journal = {Equivariant Bootstrapping for Uncertainty Quantification in Inverse Problems.},
  year = {2024},
  month = {May},
  }
  
@article{edinburgh24,
  title = {Imaging inverse problems and generating models workshop, ICMS, Edinburgh, UK},
  journal = {Towards knowledge discovery in imaging using (deep) learning: uncertainty quantification and unsupervised learning.},
  year = {2024},
  month = {April},
  }


@article{lkb24,
  title = {Complex Media Lab seminar, ENS, Paris, France},
  journal = {},
  year = {2024},
  month = {Jan},
  }



@article{imt24,
  title = {Institut de Mathematiques de Toulouse, Toulouse, France},
  journal = {Towards knowledge discovery in imaging using (deep) learning: uncertainty quantification and unsupervised learning.},
  year = {2024},
  month = {Jan},
  }

@article{paris23,
  title = {Workshop on co-design in computational imaging, IHP Paris, France},
  journal = {Tutorial: learning without ground-truth data for computational imaging problems.},
  year = {2023},
  month = {Nov},
  }

@article{purdue23,
  title = {Invited talk at Computational Imaging Group of Purdue University},
  journal = {Deep Inverse: a pytorch library for solving inverse problems with deep learning.},
  year = {2023},
  month = {Nov},
  slides = {https://enslyonfr-my.sharepoint.com/:p:/g/personal/julian_tachella_ens-lyon_fr/ES3SrXsU8cJDv9djufFNgXIBRLEjKYFhCCRNbd8gR4ENqw?e=aFCqyh},
  html = {https://colab.research.google.com/drive/1zQkt3crmbA5xcrsrqiXSeyLN6MI7LtE6?usp=sharing}
  }


@article{ICCV23,
  title = {Feature speaker LatinX in AI workshop, ICCV, Paris, France},
  journal = {Deep Inverse: a pytorch library for solving inverse problems with deep learning.},
  year = {2023},
  month = {Oct},
  slides = {https://enslyonfr-my.sharepoint.com/:p:/g/personal/julian_tachella_ens-lyon_fr/ES3SrXsU8cJDv9djufFNgXIBRLEjKYFhCCRNbd8gR4ENqw?e=aFCqyh},
  html = {https://colab.research.google.com/drive/1zQkt3crmbA5xcrsrqiXSeyLN6MI7LtE6?usp=sharing}
  }


@article{marseille23,
  title = {30 years of mathematics for optical imaging, Marseille, France},
  journal = {Deep Inverse: a pytorch library for solving inverse problems with deep learning.},
  year = {2023},
  month = {Sep},
  slides = {https://enslyonfr-my.sharepoint.com/:p:/g/personal/julian_tachella_ens-lyon_fr/EWq9rLxMLyZJvSDXmJrWLpgBOlgWUR-TjAIY_qQ_fgH3Bw?e=d6sKE7},
  html = {https://colab.research.google.com/drive/1zQkt3crmbA5xcrsrqiXSeyLN6MI7LtE6?usp=sharing}
  }


@article{iciam23,
  title = {ICIAM 2023, Tokyo, Japan},
  year = {2023},
  month = {Aug},
  project = {equivariantimaging},
  }
  
@article{london23,
  title = {Maths4DL Conference, London, UK},
  year = {2023},
  month = {Jul},
  html = {https://maths4dl.ac.uk/newsevents/conference-on-deep-learning-for-computational-physics/},
  slides = {https://enslyonfr-my.sharepoint.com/:p:/g/personal/julian_tachella_ens-lyon_fr/EVtQkRwV34dKs1q-IcoztBIBWxkdTjHHQnzLCx4d_Mp3nw?e=xOwGNN},
  project = {equivariantimaging},
  }
  
@article{creatis23,
  title = {CREATIS lab, INSA de Lyon, France, UK},
  year = {2023},
  month = {Jun},
  }
  

@article{grenoble23,
  title = {Laboratoire Jean Kuntzmann seminar, Grenoble, France},
  year = {2023},
  month = {May},
  html = {https://www-ljk.imag.fr/spip.php?article35&id=6409e00fe0db13b49f8f195f&type=SEMINAIRE},
  project = {equivariantimaging},
  }
  
@article{msia23,
  title = {Workshop on Mathematical Signal and Image Analysis (MSIA23), TUM, Raitenhaslach, Germany},
  journal = {Learning to Reconstruct Signals from Binary Measurements},
  year = {2023},
  month = {Mar},
  html = {https://www.math-conf.uni-osnabrueck.de/msia23/},
  slides = {https://docs.google.com/presentation/d/e/2PACX-1vTyhnebbBqu0GxWdIHfjLCngWba_KG7OqcZhieGoUTkmIgUoMLCYbRtrjEnZ3rfWwuKc_dkjy1_REyT/pub?start=true&loop=false&delayms=3000},
  project = {equivariantimaging},
  }


  
@article{icms23,
  title={Interfacing Bayesian statistics, deep learning, and mathematical analysis for imaging inverse problems Workshop, ICMS, Edinburgh, UK},
  journal = {Tutorial on Imaging with Equivariant Deep Learning.},
  year={2023},
  month = {Jan},
  slides = {https://www.slideshare.net/JulinAndrsTachella/tutorial-equivariance-in-imaging-icms-23pptx},
  project = {equivariantimaging},
  }


@article{neurips,
  title={NeurIPS'22, New Orleans, USA},
  journal = {Unsupervised Learning From Incomplete Measurements for Inverse Problems.},
  year={2022},
  month = {Nov},
  slides = {https://www.slideshare.net/JulinAndrsTachella/neurips22pptx},
  poster = {neurips22_poster.pdf},
  project = {equivariantimaging},
  }
  

@article{uclouvain22,
  title={ICTEAM Seminar, UCLouvain, Louvain-la-Neuve, Belgium},
  journal = {Learning to solve inverse problems without ground truth.},
  year={2022},
  month = {Oct},
  project = {equivariantimaging},
  }
  
@article{hwu22,
  title={MACS Seminar, Heriot-Watt, Edinburgh, UK},
  journal = {Learning to solve inverse problems without ground truth.},
  year={2022},
  month = {Oct},
  project = {equivariantimaging},
  }

@article{gretsi22,
  title={GRETSI'22, Nancy, France},
  journal = {Unsupervised Learning to Solve Inverse Problems: Application to Single-Pixel Imaging},
  year={2022},
  month = {Sep},
  project = {equivariantimaging},
}

@article{statmathappli22,
  title={StatMathAppli Workshop, Frejus, France},
  journal = {Learning to solve inverse problems without ground truth.},
  year={2022},
  month = {Aug},
  slides = {https://www.slideshare.net/JulinAndrsTachella/equivariant-imaging-selw22},
  project = {equivariantimaging},
  }

@article{selw22,
  title={Swiss Equivariant Learning Workshop, EPFL, Switzerland},
  journal = {Equivariant Imaging},
  year={2022},
  month = {Jul},
  project = {equivariantimaging},
  html = {https://sites.google.com/mit.edu/swiss-equivariant-learning/schedule?authuser=0},
  }

@article{icassp22,
  title={ICASSP'22, Singapore, virtual},
  journal = {Sketched RT3D: How to reconstruct billions of photons per second},
  year={2022},
  month = {May},
  project = {lidarsketching},
  poster = {icassp22_poster.pdf},
	video = {https://youtu.be/mD76r-OuNtc},
  abstract = {Single-photon light detection and ranging (lidar) captures depth and intensity information of a 3D scene. Reconstructing a scene from observed photons is a challenging task due to spurious detections associated with background illumination sources. To tackle this problem, there is a plethora of 3D reconstruction algorithms which exploit spatial regularity of natural scenes to provide stable reconstructions. However, most existing algorithms have computational and memory complexity proportional to the number of recorded photons. This complexity hinders their real-time deployment on modern lidar arrays which acquire billions of photons per second. Leveraging a recent lidar sketching framework, we show that it is possible to modify existing reconstruction algorithms such that they only require a small sketch of the photon information. In particular, we propose a sketched version of a recent state-of-the-art algorithm which uses point cloud denoisers to provide spatially regularized reconstructions. A series of experiments performed on real lidar datasets demonstrates a significant reduction of execution time and memory requirements, while achieving the same reconstruction performance than in the full data case.},
}


@article{tesa22,
  title={TeSA lab seminar, Toulouse, France},
  journal = {Equivariant Imaging: learning to solve inverse problems without ground truth.},
  year={2022},
  month = {Mar},
  project = {equivariantimaging},
  html = {https://www.tesa.prd.fr/scientific-production-tesa.p47.html},
  abstract = {In recent years, deep neural networks have obtained state-of-the-art performance in multiple imaging inverse problems ranging from medical imaging to computational photography. Networks are generally trained with pairs of signals and associated measurements. However, in various imaging problems, we usually only have access to compressed measurements of the underlying signals, hindering this learning-based approach. Learning from measurement data only is impossible in general, as the compressed observations do not contain information outside the range of the forward sensing operator. In this talk, I will present a new learning framework, called Equivariant Imaging, which overcomes this limitation by exploiting the invariance to transformations (translations, rotations, etc.) present in natural signals. I will also discuss necessary and sufficient conditions for learning without ground truth. Our proposed learning strategy performs as well as fully supervised methods and can handle noisy data. I will show results on various inverse problems, including sparse-view X-ray computed tomography, accelerated magnetic resonance imaging and image inpainting. },
}


@article{enslcolloq,
  title={ENSL Colloquium, ENS de Lyon, France},
  journal = {Equivariant Imaging: learning to solve inverse problems without ground truth.},
  year={2022},
  month = {January},
  project = {equivariantimaging},
  html = {http://www.ens-lyon.fr/PHYSIQUE/seminars/colloquium/2022-01-10},
  slides = {https://www.slideshare.net/JulinAndrsTachella/equivariant-imaging},
  abstract = {In recent years, deep neural networks have obtained state-of-the-art performance in multiple imaging inverse problems ranging from medical imaging to computational photography. Networks are generally trained with pairs of signals and associated measurements. However, in various imaging problems, we usually only have access to compressed measurements of the underlying signals, thus hindering this learning-based approach. Learning from measurement data only is impossible in general, as the compressed observations do not contain information outside the range of the forward sensing operator. In this talk, I will present a new learning framework, called Equivariant Imaging, which overcomes this limitation by exploiting the invariance to transformations (translations, rotations, etc.) present in natural signals. I will also discuss necessary and sufficient conditions for learning without ground truth. Our proposed learning strategy performs as well as fully supervised methods and can handle noisy data. I will show results on various inverse problems, including sparse-view X-ray computed tomography, accelerated magnetic resonance imaging and image inpainting. },
}


@article{topml21,
  title={TOPML Conference, Rice University, virtual},
  journal = {The role of overparameterization and optimization in CNN denoisers},
  year={2021},
  month = {April},
  project = {understandingcnns},
  slides = {https://www.slideshare.net/JulinAndrsTachella/the-role-of-overparameterization-and-optimization-in-cnn-denoisers},
  html = {http://topml.rice.edu/video-recordings/},
}

@article{bordeaux,
  title={IMB, Université Bordeaux, virtual},
  journal = {The neural tangent link between CNN denoisers and non-local filters},
  year={2021},
  month = {Jan},
  project = {understandingcnns},
  slides = {https://www.slideshare.net/JulinAndrsTachella/the-neural-tangent-link-between-cnn-denoisers-and-nonlocal-filters},
}

@article{thesis,
  title={PhD defence, ENSEEHIT, France},
  journal = {Bayesian methods for inverse problems with point clouds: applications to single-photon lidar},
  year={2020},
  month = {January},
  project = {3Dreconstruction},
  slides = {https://www.slideshare.net/JulinAndrsTachella/thesis-presentation-224996784},
}

@article{cvpr21,
  title={CVPR'21, oral presentation, virtual},
  journal = {The neural tangent link between CNN denoisers and non-local filters},
  year={2021},
  month = {June},
  project = {understandingcnns},
  poster = {cvpr21_poster.pdf},
  video = {https://youtu.be/vLxzxp2boyY},
}

@article{camsap19,
  title={CAMSAP'19, Guadaloupe, West Indies},
  journal = {Real-time color 3D reconstruction from single-photon lidar data},
  year={2019},
  month = {Dec},
  project = {3Dreconstruction},
  slides = {https://www.slideshare.net/JulinAndrsTachella/camsap19-206850606},
}


@article{eusipco19,
  title={EUSIPCO'19, La Coruña, Spain},
  journal = {Fast surface detection in single-photon lidar waveforms},
  year={2019},
  month = {Sep},
  project = {3Dreconstruction},
  slides = {https://www.slideshare.net/JulinAndrsTachella/eusipco19},
}


@article{3mt,
  title={3MT EUSIPCO'19, La Coruña, Spain},
  journal = {3D reconstruction from single-photon lidar data},
  year={2019},
  month = {Sep},
  project = {3Dreconstruction},
  video = {https://www.youtube.com/watch?v=ZFtYdjgeeYA},
  hmtl = {https://www.eurasip.org/Proceedings/Eusipco/eusipco2019/Proceedings/3mt.html},
}

@article{stem,
  title={STEM for Britain'19, Westminster Parliament, UK},
  journal = {3D reconstruction using single-photon lidar data},
  year={2019},
  month = {Mar},
  project = {3Dreconstruction},
  poster = {STEM_JTACHELLA.pdf},
  html = {https://stemforbritain.org.uk/},
}



@article{camsap19,
  title={CAMSAP'19, Guadaloupe, West Indies},
  journal = {Real-time color 3D reconstruction from single-photon lidar data},
  year={2019},
  project = {3Dreconstruction},
  month = {Dec},
  slides = {https://www.slideshare.net/JulinAndrsTachella/icassp19},
}


@article{eusipco18,
  title={EUSIPCO'18, Rome, Italy},
  journal = {Bayesian reconstruction of photon-starved images},
  year={2019},
  project = {3Dreconstruction},
  month = {Sep},
  slides = {https://www.slideshare.net/JulinAndrsTachella/bayesian-restoration-of-highdimensional-photonstarved-images},
}
