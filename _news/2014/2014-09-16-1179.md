---
layout: post
title: 'EVL of UIC Computer Science Department receives new $3 million grant from NSF'
date: 2014-09-16
tags: event
categories: events
tabs: true
---

UIC received a $3 million award from the National Science Foundation entitled &ldquo;Development of the Sensor Environment Imaging (SENSEI) Instrument&rdquo; for the period October 1, 2014 to September 30, 2017, for UIC to build the SENSEI (SENSor Environment Imaging) instrument that will capture still and motion, 3D full-sphere omnidirectional stereoscopic video and images of real-world scenes, to be viewed in collaboration-enabled, nationally networked, 3D virtual-reality systems.<br><br>
 
Congratulations to PI Maxine Brown, Director of the Electronic Visualization Lab (EVL), and to Co-PIs Robert V. Kenyon, Andrew E. Johnson and Tanya Berger-Wolf, who are all UIC Computer Science professors.<br><br>

Four other institutions will receive subawards from UIC and also contribute on the project: UC San Diego (subaward lead Truong Nguyen), University of Hawai&#8216;i at M&#257;noa (subaward lead Jason Leigh), Scripps Institution of Oceanography (subaward lead Jules Jaffe) and Jackson State University (subaward lead Francois Modave).<br><br>

<strong>Abstract:</strong><br>
Much of science is observational: scientists observe the environment to learn about behavior, trends, or changes, in order to make informed decisions, adjustments, and allowances. SENSEI images can be used to capture life-sized environments of scientific interest and extract objects&rsquo; sizes, shapes and distances. SENSEI will be designed to be replicable by the research community, with open source software and clear hardware designs, including complete 3D printing instructions for the custom sensor mounting scaffolds. SENSEI, given its 9-times-IMAX resolution and ~terapixel/minute flood of imagery, offers big data challenges as well. Specifically, SENSEI will be an integrated, distributed cyber-collaboration instrument with Big attributes: Big Resolution - configurable, portable, sensor-based camera systems; Big data - computational and storage systems; Big Displays - for 3D stereoscopic viewing; and Big Networks - for an end-to-end, tightly coupled, distributed collaboration system. The SENSEI instrument will provide hardware scaffolding for holding its sensor arrays, the data acquisition and computing platforms, telemetry and communications, as well as software.<br><br>

SENSEI will produce 4-pi steradian (fully surround) stereo video with photometric, radiometric, and photogrammetric capability for researchers in astronomy, biology, cultural heritage, digital arts, earth science, emergency preparedness, engineering, geographic information systems, manufacturing, oceanography, planetary science, archaeology, architecture, and science education. It is also intended to be an instrument of computer science and electrical engineering discovery with its variable arrays of sensors amenable to custom configurations; it will provide the means for mounting, pointing, triggering and synchronizing high-resolution sensors, as well as the flexible computational capability needed to ramp up the necessary image processing several orders of magnitude.
SENSEI concept designs

![image](https://www.evl.uic.edu/output/originals/sensei.png-srcw.jpg){:style="max-width: 100%"}
Credit: UCSD Calit2

