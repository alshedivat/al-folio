---
layout: post
title: 'Planetary-Scale Terrain Composition'
date: 2009-04-16
tags: paper
categories: papers
tabs: true
image: planetaryscale.png-srcw.jpg
---

## Planetary-Scale Terrain Composition
**Kooima, R., Leigh, J., Johnson, A., Roberts, D., Subbarao, M., DeFanti, T.**
- Location: IEEE Computer Society Digital Library
- URL: www2.computer.org/portal/web/csdl/doi/10.1109/TVCG.2009.43

[![image](https://www.evl.uic.edu/output/originals/planetaryscale.png-srcw.jpg){:style="max-width: 100%"}](https://www.evl.uic.edu/output/originals/planetaryscale.png-srcw.jpg)
- Caption: A view of the U.S. showing the NED, BMNG, and SRTM data sets, totaling 115GB
- Credit: R. Kooima, EVL

Many inter-related planetary height map and surface image map data sets exist, and more data are collected each day. Broad communities of scientists require tools to compose these data interactively and explore them via real-time visualization. While related, these data sets are often unregistered with one another, having different projection, resolution, format, and type. We present a GPU-centric approach to the real-time composition and display of unregistered-but-related planetary-scale data. This approach employs a GPGPU process to tessellate spherical height fields. It uses a render-to-vertex-buffer technique to operate upon polygonal surface meshes in image space, allowing geometry processes to be expressed in terms of image processing. With height and surface map data processing unified in this fashion, a number of powerful composition operations may be uniformly applied to both. Examples include adaptation to non-uniform sampling due to projection, seamless blending of data of disparate resolution or transformation regardless of boundary, and the smooth interpolation of levels of detail in both geometry and imagery. Issues of scalability and precision are addressed, giving out-of-core access to giga-pixel data sources, and correct rendering at scales approaching one meter.
