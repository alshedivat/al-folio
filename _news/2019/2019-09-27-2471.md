---
layout: post
title: 'Preliminary Examination Announcement: "Towards a Natural Language Interface for Exploring Data Visualization"'
date: 2019-09-27
tags: event
categories: events
tabs: true
---

PhD Student: Abhinav Kumar<br><br>
Date: September 27, 2019<br>
Time: 1:00 PM to 3:00 PM<br>
Location: Room 2068, Engineering Research Facility<br><br>
Committee:<br>
Barbara Di Eugenio (Chair and Advisor)<br>
Andrew Johnson<br>
Natalie Parde<br>
Cornelia Caragea<br>
Kallirroi Georgila<br><br>
Abstract:<br>
When exploring data visualizations, users that are novices to visualization, oftentimes struggle with translating their particular queries into an effective visual representation, which this research aims to address by automatically constructing and managing visualizations appropriately. I am particularly focusing on the language processing, which is challenging because spoken dialogue is oftentimes under-specified, leading to open interpretation and in our case potentially the wrong visualization. My main contributions are as follows. First, I am developing language processing in the multimodal setting. I worked with others in collecting and annotating a corpus of dialogue data, comprising of speech text and hand gestures, that came from data collected via human experiments. Second, I used a local context for building a module for interpreting the underlying intent of what the user says. Third, given the small size of our dataset, I augmented it using paraphrasing and showed that the intent interpretation module improved on the augmented data. As part of my proposed work, I will work on text segmentation to identify the boundaries of the local context that my current intent interpretation module operates on. I also plan to develop a model that captures references made through language and hand pointing gestures and determines the appropriate target visualizations for them.

![image](https://www.evl.uic.edu/output/originals/akumar_nlp_prelim.png-srcw.jpg){:style="max-width: 100%"}

