---
layout: post
title: 'Interactive Multi-Modal Display Spaces for Visual Analysis'
date: 2016-11-06
tags: paper
categories: papers
tabs: true
image: issp127-marrinana.png-srcw.jpg
---

## Interactive Multi-Modal Display Spaces for Visual Analysis
**Marrinan, T., Nishimoto, A., Insley, J., Rizzi, S., Johnson, A., Papka, M.**
- Location: Niagra Falls, ON, Canada
- PDF: [issp127-marrinana.pdf](/documents/issp127-marrinana.pdf)

[![image](https://www.evl.uic.edu/output/originals/issp127-marrinana.png-srcw.jpg){:style="max-width: 100%"}](https://www.evl.uic.edu/output/originals/issp127-marrinana.png-srcw.jpg)
- Caption: Collaborators gather in front of a large-scale display to share research findings and utilize a multitouch digital whiteboard to brainstorm next steps to advance their work.

Classic visual analysis relies on a single medium for displaying and interacting with data. Large-scale tiled display walls, virtual reality using head-mounted displays or CAVE systems, and collaborative touch screens have all been utilized for data exploration and analysis. We present our initial findings of combining numerous display environments and input modalities to create an interactive multi-modal display space that enables researchers to leverage various pieces of technology that will best suit specific sub-tasks. Our main contributions are 1) the deployment of an input server that interfaces with a wide array of interaction devices to create a single uniform stream of data usable by custom visual applications, and 2) three real world use cases of leveraging multiple display environments in conjunction with one another to enhance scientific discovery and data dissemination.<br><br>
<strong>Author Keywords:</strong> Multiple Display Environments; multi-user interaction; collaboration; input devices; large-scale displays; virtual reality; multi-touch screens; motion capture.<br><br>
<strong>ACM Classification Keywords:</strong> H.5.2. User Interfaces: Input devices and strategies, user centered design.
