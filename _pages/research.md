---
layout: research
title: research
tagline: <span class="font-weight-bold">Machine Learning Algorithms</span> that Make Sense
tagline_desc: in constrained and large-scale settings with applications in <strong>Advertising</strong>, <strong>Healthcare</strong>, <strong>Sustainability</strong> (Climate, Computing, Agricultural), <strong>Social Goods</strong>...
permalink: /research
definition: "<span style='font-size:1.2em'><strong>MAIL</strong></span> stands for <span style='font-size:1.2em'>practical <strong>M</strong>achine <strong>L</strong>earning and <strong>AI</strong> Lab</span>, led by <strong>Dr. Khoa D Doan</strong>."
description: "Here at <strong>MAIL</strong>, We develop computational frameworks that enable existing complex/deep models to be more suitable for practical uses. We focus on improving the following aspects of existing models: (i) training/inference, (ii) realistic assumptions, (iii) algorithmic robustness, and (iv) efficiency in constrained settings. Most of our ML/AI solutions center around large-scale approaches that have low computational complexity and require less human effort."
research_image: icon-v1.png
nav: true
weight: 10
---



<!-- Here at **MAIL**, We develop computational frameworks that enable existing complex/deep models to be more suitable for practical uses. We focus on improving the following aspects of existing models: (i) training/inference, (ii) realistic assumptions, (iii) algorithmic robustness, and (iv) efficiency in constrained settings. Most of our ML/AI solutions center around large-scale approaches that have low computational complexity and require less human effort.  -->

<!-- [more about our research](research/) -->

<!-- Khoa D Doan is currently an **Assistant Professor** in the College of Engineering and Computer Science (CECS) at VinUniversity, Vietnam. Previously, he was a **Researcher** in the Cognitive Computing Lab at [Baidu Research](http://research.baidu.com/) working with [Dr. Ping Li](http://research.baidu.com/People/index-view?id=111) on generative modeling and its applications in Information Retrieval and AI Security. He was a member of [Prof. Chandan K. Reddy](https://people.cs.vt.edu/reddy)'s lab at VT and the [Sanghani Center for Artificial Intelligence & Data Analytics](https://sanghani.cs.vt.edu/) since 2016. From May 2019 to Feb 2020, he was at [Criteo AI Lab](https://ailab.criteo.com/) in Palo Alto, CA, where he worked with [Dr. Sathiya Keerthi Selvaraj](http://www.keerthis.com/) and Dr. Fengjiao Wang. Before that, he was a Faculty Research Associate of [Earth System Science Interdisciplinary Center](http://essic.umd.edu/) at [UMD](https://www.umd.edu/) and also had a joint appointment at [NASA Goddard Space Flight Center](https://www.nasa.gov/goddard), where he worked on high-performance and distributed system research. Khoa D Doan received his Ph.D. in Computer Science from [Virginia Polytechnic Institute and State University](cs.vt.edu), and MS in Computer Science from [University of Maryland, College Park](cs.umd.edu). -->

<!-- <h1 class="post-title">{{ "Research Interests"}}</h1><a name="research_interests"></a> -->
# Research Interests

Our research focuses on understanding the practical limits of using existing ML methods in the real-world. Essential, we seek answers to the following question: *How to make ML models simpler & reliable to use in constrained settings*? **Simplicity** refers to the ability to (i) build or implement the method easily, (ii) execute the deployed model efficiently, and (iii) evolve the deployed model with less effort. **Reliability** relates to (i) whether we can rely on the model to solve the intended task well, (ii) whether this performance is preserved under frequently perturbed environments in practice such as data corruptions or distributional changes, and (iii) whether the model is resilient to (i.e., its performance is not significantly affected by) various forms of security attacks such as adversarial examples and causal attacks. In this sense, we believe that many existing ML methods, including those with *complex* deep neural networks, are *reliable* but *not yet easy-to-use* because they do not satisfy various constraints seen in real-world applications. We also strongly believe the effort to answer this question will help us truly realize the potential of AI/ML methodology in practice.  

Our goal, therefore, is to develop computational frameworks that enable existing complex/deep models to be more suitable for practical uses. We focus on improving the following aspects of existing models: (i) **training/inference**, (ii) **realistic assumptions**, (iii) **algorithmic robustness**, and (iv) **efficiency in constrained settings**. Most of our ML/AI solutions center around generative-based approaches that have low computational complexity and require less human effort. Currently, our research activities include, but not limited to, the following themes (*with selected publications*):

<span style='font-size:1.2em'>**Information Retrieval and Applications**</span>

* Interpretable Graph Similarity Computation via Differentiable Optimal Alignment of Node Embeddings (*SIGIR* 2021 by Doan et al.)
* Efficient Implicit Unsupervised Text Hashing using Adversarial Autoencoder (*WWW* 2020 by Doan et al.)
* Image Hashing by Minimizing Discrete Component-wise Wasserstein Distance (*arxiv* 2021 by Doan et al.)
* Generative Hashing Network (*ACCV* 2022 by Doan et al.)
* EBM Hashing Network (*Under Submission* 2021 by Doan et al.)
* One Loss for Quantization: Deep Hashing with Discrete Wasserstein Distributional Matching  (*CVPR* 2022 by Doan et al.)
* Asymmetric Hashing for Fast Ranking via Neural Network Measures  (*SIGIR* 2023 by Doan et al.)

<span style='font-size:1.2em'>**Generative Models**</span>

* Image Generation Via Minimizing Frechet Distance in Discriminator Feature Space (*arxiv* 2021 by Doan et al.)
* Regression via implicit models and optimal transport cost minimization (*arxiv* 2020 by Manchanda et al.)

<span style='font-size:1.2em'>**AI Backdoor Security with Generative Models**</span>

* Backdoor Attack with Imperceptible Input and Latent Modification (*NeurIPS* 2021 by Doan et al.)
* LIRA: Learnable, Imperceptible and Robust Backdoor Attacks (*ICCV* 2021 by Doan et al.)
* Adversarial Defenses for Vision Transformers   (*Under Submission* 2022 by Peng et al.)
* Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class (*NeurIPS* 2022 by Doan et al.)
* Defending backdoor attacks on vision transformer via patch processing  (*AAAI* 2023 by Doan et al.)

<!-- # Industry Interests -->