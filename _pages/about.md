---
layout: about
title: about
permalink: /
subtitle: chawins AT berkeley DOT edu.

profile:
  align: right
  image: profile_pic.png
  image_circular: false # crops the image to make it circular
  address: >
    <p>"Chawin"</p>
    <p>99.3% confidence</p>
    <p>(he/him/his)</p>

news: true  # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

[CV](/assets/pdf/Chawin_Sitawarin_CV.pdf) &nbsp;&nbsp;&nbsp;&nbsp; [Google Scholar](https://scholar.google.com/citations?hl=en&authuser=1&user=AxUAEQ4AAAAJ)

Hello! My name is Chawin Sitawarin. I am a PhD student in Computer Science at UC Berkeley, and I am a part of [the security group](https://security.cs.berkeley.edu/), [Berkeley Artificial Intelligence Research (BAIR)](https://bair.berkeley.edu/) and [Berkeley DeepDrive (BDD)](https://bdd-data.berkeley.edu/). My advisor is [Prof. David Wagner](https://people.eecs.berkeley.edu/~daw/).

I am broadly interested in the intersection between machine learning and computer security. Most of my current and previous works are in the domain of adversarial machine learning, particularly adversarial examples and robustness of machine learning algorithms. If you are confused about my profile picture, please see this [paper](https://arxiv.org/pdf/1412.6572.pdf).

Previously, I graduated from Princeton University in 2018 where I was very fortunate to be advised by [Prof. Prateek Mittal](https://www.princeton.edu/~pmittal/), [Prof. Peter Ramadge](http://faculty.ee.princeton.edu/ramadge/doku.html), and [Prof. Alejandro Rodriguez](http://faculty.ee.princeton.edu/arodriguez/).

I used to keep track of papers on adversarial examples, but I stopped after the number of papers has become overwhelming. You can still find the list [here](https://github.com/chawins/Adversarial-Examples-Reading-List) (last update: Sep 2019).
