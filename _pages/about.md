---
layout: about
title: about
permalink: /
profile:
  align: right
  image: prof_pic.png
news: true  # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={false}"
social: true  # includes social icons at the bottom of the page
---
Interested in AI Safety
\\
\\
Hi! I am Samyak. I am currently working at Five AI at Oxford, where I am advised by [Puneet Dokania](https://puneetkdokania.github.io). Previously, I have worked with [David Krueger](https://www.kasl.ai) at Cambridge University and [Venkatesh Babu](https://val.cds.iisc.ac.in/) at [Indian Institute of Science, Bangalore](https://iisc.ac.in/). Recently, I completed my bachelors and masters in [Computer Science](https://www.iitbhu.ac.in/dept/cse) at the [Indian Institute of Technology (BHU) Varansi](https://www.iitbhu.ac.in/), where my [thesis](https://drive.google.com/file/d/1J0bry6gDU5k_K3iMIRRrCV865wM9Ww49/view) focussed on understanding and improving adversarial robustness of neural networks. For the last few years I have been broadly working on Machine Learning with a particular focus on Adversarial Robustness, Generalization and Mechanistic Interpretability. Moving forward, I am excited about contributing in the field of AI Safety.
\\
\\
Recently, I completed my interenship at Cambridge University, where I worked on [understanding fine-tuning using mechanistic interpretability](https://arxiv.org/abs/2311.12786). Before that I worked at the [Vision and AI Lab](https://val.cds.iisc.ac.in/) for more than three years where my projects were related to adversarial robustness and understanding loss landscape of neural networks, which have been published at the following [venues](./publications).
\\
\\
During my undergrad, I got an opportunity to work with [Debarghya Ghoshdastidar](https://www.professoren.tum.de/en/ghoshdastidar-debarghya) at the Technical University of Munich where I built an understanding of the learning dynamics and loss landscape of linear neural networks.
Besides this I actively participate in machine learning  and computer vision conferences and have served as a reviewer at multiple conferences and won outstanding reviewer awards at ICLR 2022 and CVPR 2022.
Here is the link to my [CV](https://drive.google.com/file/d/1WGkicIJ8dW3nZ51kVl_ZNyv66our7V7k/view?usp=sharing).
\\
\\
Broadly I am interested in research topics related to AI safety, in particular:
\\
**Alignment:** Unlearning, RLHF fine-tuning
\\
**Mechanistic Interpretability:** Science of Deep Learning
\\
**Robustness:** Adversarial Robustness, OOD Robustness
\\
**Generalization and Foundations of ML:** Mode Connectivity, Loss landscape sharpness, Learning dynamics
\\
**Role of Data in Learning:** Curating data to build safe models
