---
layout: about
title: about
permalink: /
# subtitle: <a href='#'>Affiliations</a>. Address. Contacts. Moto. Etc.

profile:
  align: right
  image: pfp.jpg
  image_circular: false # crops the image to make it circular
  # address: >
  #   <p>555 your office number</p>
  #   <p>123 your address street</p>
  #   <p>Your City, State 12345</p>

news: true  # includes a list of news items
latest_posts: true  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page 
---

<!-- I am currently relocating my personal website. You can view my original website [here](https://andre-ye.github.io/andre-ye.github.io-retired/){:target="_blank"} while I am transferring. -->

I am an honors, Phi Beta Kappa, and Mary Gates scholar at the University of Washington studying philosophy and computer science, minoring in mathematics and history.
My current specific research interests are twofold: (*i.*) how can we design **non-human intelligences** to **aid [human philosophical practice](https://arxiv.org/abs/2404.04516){:target="_blank"}** and address **metaphilosophical problems**? (*ii.*) how can [**philosophical concerns**](https://andre-ye.github.io/assets/pdf/Ranjay%20Group%20-%20Philosophy%20x%20AI.pdf){:target="_blank"} and insights help us build [better AI](https://arxiv.org/abs/2310.14356){:target="_blank"} and **human-AI [interactions](/assets/pdf/CSE%20582%20Poster.pdf)**?
My general intellectual interests are in philosophy of AI, phenomenology, philosophy of science, and computer vision.
Please see my [research agenda](/agenda) and [CV](/cv) for more details.
I have written a few [essays](/writing/philosophy){:target="_blank"} in philosophy, [two](/writing/mdldna){:target="_blank"} [books](/writing/mdl4td){:target="_blank"} on deep learning, a little bit of [fiction](/writing/fiction){:target="_blank"}, and many data science [articles](https://andre-ye.medium.com/){:target="_blank"}.
My email is `andreye [at] uw [dot] edu`.

<br>

<center>
<img src="/assets/img/new-shot.png" width="100%" />
</center>

<br>

<center>
<img src="\assets\img\ghost-portraits.png" width="100%" />
</center>
<small>
  Composite image of The Disintegration of the Persistence of Memory (Dali), Edward Bellamy (GAN), Guernica (Picasso), still from Battleship Potemkin (Eisenstein), Relativity (Escher).
</small>

<br>

<center>
<a href="https://info.flagcounter.com/42Y6"><img src="https://s11.flagcounter.com/count2/42Y6/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" alt="Flag Counter" border="0"></a>
</center>



<!-- My interest is in the philosophy of technology and AI.
I think that we need to understand the metaphysical and political structure of data and models in order to understand their ethical/normative character.

Some questions which excite me are:
Can we develop an ontology of datasets, models, and information (flow)?
What does this mean for ethical questions of consent, privacy, and property in human-AI interactions?
Does AI stand for $$\{$$epistemic, political, ethical$$\}$$ universality? -- and what are complications with value pluralism and other analytic ethical frameworks for AI which assume either universality or particularity?

My previous work has been in varied areas of computer vision and HCI, with a focus on human subjectivity and challenging singular ground truths.
I have worked with
$$\{$$
[Sebastin Santy](https://sebastinsanty.com/){:target="_blank"},
[Ranjay Krishna](https://ranjaykrishna.com/index.html){:target="_blank"}, 
[Amy Zhang](https://homes.cs.washington.edu/~axz/){:target="_blank"} 
 $$\}$$
on cross-cultural [perceptual differences](/projects/cv_cognition/){:target="_blank"} in vision understanding models;
$$\{$$[Jared Moore](https://jaredmoore.org/){:target="_blank"}
and Mark Pock$$\}$$ on moral meaning and [social intentionality](/projects/social_intentionality/){:target="_blank"} in LLMs;
the [Social Futures Lab](https://social.cs.washington.edu/){:target="_blank"}
on [uncertainty representation](/projects/confidence_contours/){:target="_blank"} in segmentation models;
the [Najafian Lab](https://dlmp.uw.edu/research-labs/najafian/najafian-lab-members){:target="_blank"}
on the [segmentation](/projects/foot_process_seg/){:target="_blank"} of kidney structures. -->

<!-- I have written a few [essays](/writing/philosophy){:target="_blank"} in philosophy, [two](/writing/mdldna){:target="_blank"} [books](/writing/mdl4td){:target="_blank"} on deep learning, a little bit of [fiction](/writing/fiction){:target="_blank"}, and many [data science articles](https://andre-ye.medium.com/){:target="_blank"}.  -->

<!-- Outside of academics, I enjoy listening to [lectures](https://www.youtube.com/watch?v=06KiOj6gjbs){:target="_blank"} by Slavoj Zizek (my favorite undead philosopher), playing piano, learning Russian (and French... someday). -->

<!-- **Philosophy Interest Statement.** Aphorism 127 in Adorno’s *Minima Moralia* declares, “Intelligence is a moral category.” Every rational and intellectual endeavor expresses an ethical orientation. One usually takes from this that we need a meditation on the ethical waste and peril of human intellectual histories. But intelligence is no longer obviously an anthropocentric feature. My academic interest is in subjecting non-human intelligences (“AI”) to this very sort of meditation. Is the only ethical significance of AI the one that humans imbue into it? Might AI’s persistent exteriority to “HI” (Human Intelligence) better capture truths which themselves elude the rational (human) ego? Can AI ‘do’ philosophy, and does it represent a break in the history of philosophy?

**Computer Science Interest Statement.**
Computer vision research builds datasets that assign a single human label to images. Models are often trained under the implicit assumption that this label is indisputable. I am interested in challenging this assumption by exploring how data and machine learning systems can better reflect and engage with human subjectivity across a wide variety of real-world problems.
*Updated version forthcoming.*
See my [CRA OUR award research statement](/assets/pdf/cra-research-statement-2023.pdf){:target="_blank"} and [personal statement](/assets/pdf/cra-personal-statement-2023.pdf){:target="_blank"}. -->