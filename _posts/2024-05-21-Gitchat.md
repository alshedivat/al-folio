---
layout: post
title: Building a Github Chat Interface with LangChain, LM Studio, and FAISS
date: 2024-05-26 14:30:16
description: Learn how to leverage LangChain, LM Studio, and FAISS to create a chat interface for Github repositories.
tags: LangChain, LMStudio, FAISS, Docker, Github
categories: NLP
featured: true
---

In this tutorial, we'll explore using LangChain, LM Studio, and FAISS to create a chat interface for interacting with Github repositories. This project will involve cloning a Github repo using GitLoader from LangChain, splitting the repository into chunks of text with a recursive text splitter, creating a vector database for these split documents using FAISS, and connecting user queries to a local LM Studio for answering questions about the repository. Finally, we'll deploy the project using Docker and create a Streamlit app where users can supply a Github repo and ask questions about it.

#### Cloning Github Repo with LangChain's GitLoader
We'll use LangChain's GitLoader to clone the desired Github repository. This allows us to access the repository's contents programmatically. You may need to authenticate with github (refer to [GitPython](https://github.com/gitpython-developers/GitPython))

#### Connecting User Queries to LM Studio
Users will interact with the chat interface by supplying questions about the Github repository. These queries will be connected to a local instance of LM Studio (defined as llm), a powerful language model fine-tuned for generating human-like responses. LM Studio will answer the user's questions based on the information stored in the vector database.

{::nomarkdown}
{% assign jupyter_path = "assets/jupyter/gitload_1.ipynb" | relative_url %}
{% capture notebook_exists %}{% file_exists assets/jupyter/gitload_1.ipynb %}{% endcapture %}
{% if notebook_exists == "true" %}
{% jupyter_notebook jupyter_path %}
{% else %}

<p>Sorry, the notebook you are looking for does not exist.</p>
{% endif %}
{:/nomarkdown}

Note: repo_path is the path to save the cloned repo and branch is the branch of the repo to be cloned.

#### Splitting Repo into Text Chunks
Next, we'll use a recursive text splitter to divide the repository's contents into manageable text chunks. This step is crucial for processing and analyzing large volumes of text efficiently.
{::nomarkdown}
{% assign jupyter_path = "assets/jupyter/gitload_2.ipynb" | relative_url %}
{% capture notebook_exists %}{% file_exists assets/jupyter/gitload_2.ipynb %}{% endcapture %}
{% if notebook_exists == "true" %}
{% jupyter_notebook jupyter_path %}
{% else %}

<p>Sorry, the notebook you are looking for does not exist.</p>
{% endif %}
{:/nomarkdown}

Note that we overlap each chunk by 20 characters to capture more context about the chunks.

#### Creating Vector Database with FAISS
Once we have the text chunks, we'll create a vector database using FAISS.

{::nomarkdown}
{% assign jupyter_path = "assets/jupyter/gitload_3.ipynb" | relative_url %}
{% capture notebook_exists %}{% file_exists assets/jupyter/gitload_3.ipynb %}{% endcapture %}
{% if notebook_exists == "true" %}
{% jupyter_notebook jupyter_path %}
{% else %}

<p>Sorry, the notebook you are looking for does not exist.</p>
{% endif %}
{:/nomarkdown}

#### Building Streamlit App and Docker Deployment
Finally, we'll build a user-friendly Streamlit app where users can input the Github repository and their questions. The app will communicate with the backend components, including LangChain, FAISS, and LM Studio, to provide seamless interaction. We'll containerize the entire project using Docker for easy deployment and scalability.

{::nomarkdown}
{% assign jupyter_path = "assets/jupyter/gitload_4.ipynb" | relative_url %}
{% capture notebook_exists %}{% file_exists assets/jupyter/gitload_4.ipynb %}{% endcapture %}
{% if notebook_exists == "true" %}
{% jupyter_notebook jupyter_path %}
{% else %}

<p>Sorry, the notebook you are looking for does not exist.</p>
{% endif %}
{:/nomarkdown}

The full implementation of the components of the project will be uploaded on my GitHub page!
