---
layout:     post
title:      LLVM Machine Passes
summary:    The dark side of LLVM compilation flow.
categories: llvm c++
tags:       [llvm, c++, assembly]
---

LLVM has a very rich set of analysis and transformation passes dedicated to operate on the Intermediate Representation (IR) format which is used as a common abstraction between the frontend operating on the very high level of source code, and the backend responsible for lowering the IR into a respective target ISA. The IR is provided in a static single assignment form (SSA)[^1]. The primary feature of SSA is the requirement of a single assignment to every variable. Although LLVM as a project suffers from many undocumented features and tools, the documentation on IR passes is suprisingly good, including a propably complete list of available passes[^2] and a quite good introduction[^3] on implementing passes, although the content on pass manager and specifying requirements could be updated to reflect the difference between legacy and modern pass manager.

But what happens when we try to analyze the machine representation of the code on the target side? According to code generator documentation[^4] and the avery good article 'Life of an instruction in LLVM'[^5], IR building blocks have their counterparts in the backend. An IR function is represented by a [`MachineFunction`](https://llvm.org/docs/CodeGenerator.html#the-machinefunction-class) on the backend side. `MachineFunction` contains possibly multiple [`MachineBasicBlock`](https://llvm.org/docs/CodeGenerator.html#the-machinebasicblock-class) instances, and machine basic blocks contain instances of [`MachineInstruction`](https://llvm.org/docs/CodeGenerator.html#the-machineinstr-class). These three types have different relationships with their IR counterparts. A `MachineFunction` always represents an IR `Function` while the `MachineBasicBlock` **might** map a BasicBlock but it does not have to! That's why `getFunction()` returns a reference and `getBasicBlock()` returns a pointer which might be null. Finally, the machine instruction does not correspond directly to IR `Instruction` at all.

But why is there a one-to-many mapping in basic blocks? The example below explains how the abstracted view of the machine in the IR can't match perfectly the actual assembly.

{% highlight c++ %}
    {% include code/machine_pass_sum.cpp %}
{% endhighlight %}

This code is compiled in clang with flags `-O3 -fno-vectorize -fno-unroll-loops` to keep the code simple; loop vectorization and unrolling will create additional machine basic blocks as well but the representation is harder to understand. 

```llvm
    {% include code/machine_pass_sum.ll %}
```

This is the most basic representation of our code - if the second parameter `length` is greater than zero, the control flow reaches loop preheader with label `4` and then loop with label `8` where the actual computation is performed. The exit block `6` defines the final result returned from the function with a `phi node` which selects either a constant 1 or the loop result, depending on whether the loop has executed at least one iteration. PHI nodes are a very fundamental concepts in the SSA representation but they don't exist in hardware. Therefore, in this case the basic block is duplicated as we can see on the listing below.

```nasm
    {% include code/machine_pass_sum_machine.ll %}
```

The exit block from IR corresponds to the machine basic block `bb.2` which returns the value in vector register `xmm0`. Additionally, a second exit block `bb.1` is provided for the case when loop is not executed at all. A similar pattern can be seen in the assembly for x86 target where the new block moves the constant value to the register before executing `retq`.

From an LLVM bitcode, we can go directly generate object file which in our case is stored as an x86-64 ELF format, by using the LLVM static compiler [`llc`](https://llvm.org/docs/CommandGuide/llc.html)

```
llc -filetype=obj file.bc -o file.o
```

with the option `-filetype=obj`. One can also generate an assembly listing

```
llc -S file.bc -o file.s
llvm-mc -filetype=obj file.bc -o file.o
```

Additionaly, the flag `-asm-show-inst` generates the listing with mapping to LLVM machine instructions and operands in comments. When building C/C++ programs, these steps are wrapped inside `clang` tool and hidden from the user [^6].

The well-documented and properly explained infrastracture ends as soon as we try to write and run passes on machine code representation. It sounds from this [November 2015](http://lists.llvm.org/pipermail/llvm-dev/2015-November/092058.html) discussion on the mailing list that there's no way of running the pass dynamically during target code generation. llc docs explain that the `-load` option, known also in opt, is used to dynamically load targets, not passes. For the purpose of this tutorial, we want to write a pass printing machine blocks and basic statistics on size and correspondence to IR block. `llc` already offers an ability to print out machine instructions after every optimization step by using the flag `-print-machineinstrs`. The contents of this tutorial are mostly based on the information found on LLVM mailing list[^7].

The code generation operates in several phases which are responsible for selecting instructions, allocating registers. performing late optimizations such as [peephole optimizations](https://en.wikipedia.org/wiki/Peephole_optimization) and emitting the code[^8]. We want to run our pass quite late, just after target optimizations and before the lowering of machine instructions to target code. Since there's no way to dynamically load the pass, we need to statically embed our pass in X86 target generation chain.

First, we implement our machine pass that visits functions in the code. As the naming scheme suggests, a machine counterpart of a FunctionPass is simply a [MachineFunctionPass](http://llvm.org/doxygen/classllvm_1_1MachineFunctionPass.html). Only a single function `runOnFunction` needs to be implemented . Since we want to print a basic information on block size, it might look like this:

{% highlight c++ %}
    {% include code/machine_pass_printer.cpp %}
{% endhighlight %}

We use the macro [`INITIALIZE_PASS`](http://llvm.org/doxygen/PassSupport_8h.html) as a first step of pass registration. It defines a function `initializePASSNAMEPass` in namespace `llvm` and we need to provide an additional declaration. Furthermore, we need to supply a function returning a dynamically allocated pass object. Both function are used by the target configuration to add our pass to the pipeline.

The we need a forward declaration of the create function in [lib/Target/X86/X86.h](https://github.com/llvm-mirror/llvm/blob/d2b1fb11d3f3e5d88bc57c8e0154d367e0e48164/lib/Target/X86/X86.h#L130)

```c++
namespace llvm {
    ...
    FunctionPass *createMachinePrinter();
}
```

Forward decalarations allow compiling the target configuration independently from passes implementation. Thus, passes can be developed and improved without a significant project rebuild. Now we need to insert our analysis pass into X86 target configuration. We start in [`lib/Target/X86/X86TargetMachine.cpp`](https://github.com/llvm-mirror/llvm/blob/master/lib/Target/X86/X86TargetMachine.cpp) with a forward declaration and a call to initialization function in [`lib/Target/X86/X86TargetMachine.cpp`](https://github.com/llvm-mirror/llvm/blob/master/lib/Target/X86/X86TargetMachine.cpp#L59). 

```c++
namespace llvm {
  void initializeMachinePrinterPass(PassRegistry &);
}

extern "C" void LLVMInitializeX86Target() {
  PassRegistry &PR = *PassRegistry::getPassRegistry();
  ...
  initializeMachinePrinterPass(PR);
}
```

Since I want to look at machine code after all implementations have been finished, the pass is called just at the very end:

```c++
void X86PassConfig::addPreEmitPass2() {
  ...
  addPass(createMachinePrinter());
}
```

As the last step we modify the `CMakeLists.txt` in [`lib/Target/X86/CMakeLists.txt`](https://github.com/llvm-mirror/llvm/blob/d2b1fb11d3f3e5d88bc57c8e0154d367e0e48164/lib/Target/X86/CMakeLists.txt) to add the new .cpp file to `sources` list. The new pass should be available when using llc to build x86 targets.

As we see, this process is not complicated and one can set up a machine pass prototype in just a few minutes. It's a pity that this process is not so well documented and supported as IR passes. And as far as machine basic block statistics are concerned, this method is reliable only when static information is concerned. Dynamic block counts need profiling information that is available on the IR level, and the one-to-many mapping between IR and machine basic block prevent us from obtaining a complete and accurate result. For that purpose one needs to use other instrumentation tool, for example the `Pin` tool which is capable of counting [basic block instances](https://software.intel.com/sites/landingpage/pintool/docs/81205/Pin/html/index.html#inscount1).


[^1]: [SSA on Wikipedia](https://en.wikipedia.org/wiki/Static_single_assignment_form), a [free textbook on SSA](http://ssabook.gforge.inria.fr/latest/book.pdf) provided by Inria - work in progress!
[^2]: [LLVM Passes](https://llvm.org/docs/Passes.html)
[^3]: [Writing an LLVM Pass](http://llvm.org/docs/WritingAnLLVMPass.html)
[^4]: [The LLVM Target-Independent Code Generator](http://llvm.org/docs/CodeGenerator.html)
[^5]: [Life of an instruction LLVM](https://eli.thegreenplace.net/2012/11/24/life-of-an-instruction-in-llvm), Eli Bendersky
[^6]: [January 2018](http://lists.llvm.org/pipermail/llvm-dev/2018-January/120165.html) mailing list discussion explains the differences between building an application with various pipelines based on clang, opt and llc.
[^7]: [November 2015](http://lists.llvm.org/pipermail/llvm-dev/2015-November/092030.html) discussion on writing a machine pass, [April 2014](http://lists.llvm.org/pipermail/llvm-dev/2014-May/072987.html) discussion which brings the problem of finding correspondence between IR and machine instructions. The mentioned `-debug-ir` was deprecated and [removed in November 2014](https://reviews.llvm.org/rL222945). As of October 2018, there's an [open review for a  new debug pass](https://reviews.llvm.org/D40778). [July 2016](https://groups.google.com/forum/#!searchin/llvm-dev/debug-ir%7Csort:date/llvm-dev/PP8C_96rhuI/3ddvu9MVCQAJ) question on matching machine instructions with IR, no answers unfortunately.
[^8]: [High-level design of code generator](http://llvm.org/docs/CodeGenerator.html#high-level-design-of-the-code-generator)
